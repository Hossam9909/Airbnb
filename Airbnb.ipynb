{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tabulate import tabulate\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# 1. Load Data Function\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load a CSV file into a DataFrame with error handling.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): Path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Loaded DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Successfully loaded data from {file_path}\\n\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Error: The file {file_path} was not found.\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        raise ValueError(\"Error: The file is empty.\")\n",
    "    except pd.errors.ParserError:\n",
    "        raise ValueError(\"Error: The file could not be parsed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Exploratory Data Analysis\n",
    "def display_data_info(df):\n",
    "    \"\"\"\n",
    "    Display detailed information about the DataFrame, including:\n",
    "    - Number of rows and columns.\n",
    "    - Number of columns with missing data.\n",
    "    - Data type of each column.\n",
    "    - Summary statistics for numerical and categorical data.\n",
    "    - Percentage of missing values per column.\n",
    "    - Number of duplicate rows.\n",
    "    - Number of unique values per column.\n",
    "    - Correlation matrix for numerical columns.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame.\n",
    "    \"\"\"\n",
    "    print(\"\\nAnalyzing the dataset...\\n\")\n",
    "    print(f\"Number of rows: {df.shape[0]}\")\n",
    "    print(f\"Number of columns: {df.shape[1]}\")\n",
    "\n",
    "    # Missing Data Information\n",
    "    missing_counts = df.isna().sum()\n",
    "    num_cols_missing = (missing_counts > 0).sum()\n",
    "    print(f\"Number of columns with missing data: {num_cols_missing}\")\n",
    "\n",
    "    if num_cols_missing > 0:  # Only show details if there are any missing values.\n",
    "        missing_percentage = (missing_counts / len(df)) * 100\n",
    "        missing_info = pd.DataFrame({\n",
    "            'Missing Count': missing_counts,\n",
    "            'Missing Percentage': missing_percentage\n",
    "        }).round(2)\n",
    "        print(\"\\nMissing Value Information:\")\n",
    "        print(tabulate(missing_info, headers='keys', tablefmt='pretty', showindex=True))  #Show index (column names)\n",
    "\n",
    "\n",
    "    # Data Type Information\n",
    "    print(\"\\nData types of each column:\")\n",
    "    print(tabulate(df.dtypes.reset_index(), headers=['Column', 'Data Type'], tablefmt='pretty'))\n",
    "\n",
    "    # Summary Statistics (Numerical)\n",
    "    print(\"\\nSummary statistics for numerical data:\")\n",
    "    numerical_summary = df.describe(include=np.number).round(2)\n",
    "    print(tabulate(numerical_summary, headers='keys', tablefmt='pretty'))\n",
    "\n",
    "\n",
    "    # Summary Statistics (Categorical) - Improved\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns #Handles both object and category dtypes\n",
    "    if categorical_cols.size > 0:\n",
    "        print(\"\\nSummary statistics for categorical data:\")\n",
    "        categorical_summary = df[categorical_cols].describe().T\n",
    "        categorical_summary['Distinct Count'] = df[categorical_cols].nunique() #Adds distinct count, handles missing values better.\n",
    "        print(tabulate(categorical_summary, headers='keys', tablefmt='pretty'))\n",
    "\n",
    "    # Unique Values\n",
    "    print(\"\\nNumber of unique values per column:\")\n",
    "    print(tabulate(df.nunique().reset_index(), headers=['Column', 'Unique Values'], tablefmt='pretty'))\n",
    "\n",
    "\n",
    "    # Correlation Matrix (Numerical)\n",
    "    print(\"\\nCorrelation matrix for numerical columns:\")\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    correlation_matrix = numeric_df.corr().round(2)\n",
    "    print(tabulate(correlation_matrix, headers='keys', tablefmt='psql'))  # 'psql' is visually nicer for matrices\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Clean Data Function\n",
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "    Clean the dataset by removing empty columns and preprocessing 'last_review'.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input DataFrame to clean.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Cleaned DataFrame with:\n",
    "        - Columns with 100% missing values removed.\n",
    "        - 'last_review' column converted to datetime and missing values imputed.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Remove columns with all missing values\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "\n",
    "    # Convert 'last_review' to datetime and fill missing with placeholder\n",
    "    df.loc[:, 'last_review'] = pd.to_datetime(df['last_review'], errors='coerce').dt.date\n",
    "    df.loc[:, 'last_review'] = df['last_review'].fillna('No reviews')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Impute Missing Values\n",
    "def impute_missing_values(df):\n",
    "    \"\"\"\n",
    "    Impute missing values for numerical columns.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The DataFrame with imputed values.\n",
    "    \"\"\"\n",
    "    # Impute 'reviews_per_month' and 'price' with the median\n",
    "    \n",
    "    # Rationale: The median is robust to outliers and provides a central value for imputation.\n",
    "    df['reviews_per_month'] = df['reviews_per_month'].fillna(df['reviews_per_month'].median())\n",
    "    \n",
    "    # Rationale: Using the median for price ensures outlier influence is minimized.\n",
    "    df['price'] = df['price'].fillna(df['price'].median())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. Plot Numerical Histograms\n",
    "def plot_numerical_histograms(df):\n",
    "    \"\"\"Plots histograms for numerical columns, skipping empty ones.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    # Select numerical types\n",
    "    numerical_cols = df.select_dtypes(include=np.number)\n",
    "\n",
    "    cols_to_plot = []  # Keep track of numerical and non-empty columns.\n",
    "    for col in numerical_cols:\n",
    "        if not pd.isna(df[col]).all():  # Check if not all values are NaN\n",
    "            cols_to_plot.append(col)\n",
    "    \n",
    "    if not cols_to_plot:  # If there are no numerical columns to plot, return a message.\n",
    "        print(\"No numerical columns to plot in DataFrame.\")\n",
    "        return\n",
    "\n",
    "    num_cols = len(cols_to_plot)  # Only includes non-empty columns.\n",
    "    num_rows = (num_cols + 2) // 3  # Correct the number of rows to display.\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=num_rows, ncols=3, figsize=(12, 8))\n",
    "    axes = axes.ravel()  # Flatten axes array for iteration.\n",
    "\n",
    "    for i, col in enumerate(cols_to_plot):  # Only iterate through non-empty cols\n",
    "        ax = axes[i]\n",
    "        sns.histplot(df[col], bins=30, kde=True, ax=ax)\n",
    "        ax.set_title(col)\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # Turn off any extra axes if the number of plots is not a multiple of 3\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.Display DataFrame in chunks of rows and columns\n",
    "def display_dataframe_in_chunks(df):\n",
    "    \"\"\"\n",
    "    Display the DataFrame in chunks of rows and columns, with user customization.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to display.\n",
    "\n",
    "    Behavior:\n",
    "    - Allows users to specify the number of rows and columns to display interactively.\n",
    "    - Displays the specified number of rows and columns at a time.\n",
    "    - Prompts the user to continue viewing the next chunk of rows and columns.\n",
    "    \"\"\"\n",
    "\n",
    "    num_rows, num_cols = df.shape  # Get the number of rows and columns\n",
    "\n",
    "    # Prompt user for chunk size\n",
    "    while True:\n",
    "        try:\n",
    "            chunk_size = input(f\"Enter the number of rows to display per chunk (default is 10, total rows: {num_rows},\n",
    "                               total columns: {num_cols}): \").strip()\n",
    "            chunk_size = int(chunk_size) if chunk_size else 10  # Default to 10 if input is empty\n",
    "\n",
    "            if chunk_size <= 0:\n",
    "                print(\"Chunk size must be a positive integer. Please try again.\")\n",
    "                continue\n",
    "            break  # Exit input loop if successful\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a valid integer.\")\n",
    "\n",
    "    for i in range(0, len(df), chunk_size):\n",
    "        chunk = df[i:i + chunk_size]\n",
    "        print(tabulate(chunk, headers='keys', tablefmt='pretty'))\n",
    "\n",
    "        if i + chunk_size < len(df):\n",
    "            if input(\"Display next chunk? (yes/no): \").strip().lower() != 'yes':\n",
    "                break\n",
    "\n",
    "    print(\"End of DataFrame reached.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Function for Scatter Plot\n",
    "def plot_scatter(x, y, data, title, xlabel, ylabel, hue=None):\n",
    "    \"\"\"\n",
    "    Helper function to create scatter plots.\n",
    "\n",
    "    Parameters:\n",
    "    x (str): Column name for x-axis.\n",
    "    y (str): Column name for y-axis.\n",
    "    data (pd.DataFrame): DataFrame containing the data.\n",
    "    title (str): Title of the plot.\n",
    "    xlabel (str): Label for x-axis.\n",
    "    ylabel (str): Label for y-axis.\n",
    "    hue (str, optional): Column name for color coding.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.scatterplot(x=x, y=y, data=data, alpha=0.6, hue=hue, palette='cool')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    if hue:\n",
    "        plt.legend(title=hue, loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Function for Bar Plot\n",
    "def plot_bar(data, x, y, hue=None, title='', xlabel='', ylabel='', rotation=0):\n",
    "    \"\"\"\n",
    "    Helper function to create bar plots.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): DataFrame containing the data.\n",
    "    x (str): Column name for x-axis.\n",
    "    y (str): Column name for y-axis.\n",
    "    hue (str, optional): Column name for hue (categorical variable).\n",
    "    title (str): Title of the plot.\n",
    "    xlabel (str): Label for x-axis.\n",
    "    ylabel (str): Label for y-axis.\n",
    "    rotation (int, optional): Rotation angle for x-tick labels.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # If hue is provided, use it for coloring\n",
    "    if hue:\n",
    "        sns.barplot(data=data, x=x, y=y, hue=hue, palette='cool')\n",
    "    else:\n",
    "        sns.barplot(data=data, x=x, y=y)  # Use default colors if no hue is provided\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xticks(rotation=rotation, ha='right')\n",
    "    \n",
    "    # Check if hue is provided and has unique values for legend\n",
    "    if hue: # Improved legend handling\n",
    "       handles, labels = plt.gca().get_legend_handles_labels()\n",
    "       if handles: # Check if any handles/labels exist.\n",
    "           plt.legend(handles, labels, title=hue, loc='best')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Analyze price factors\n",
    "def analyze_airbnb_price_factors(df):\n",
    "    \"\"\"\n",
    "    Analyze the factors influencing Airbnb listing prices using linear regression.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The preprocessed DataFrame containing Airbnb data.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the coefficients of the linear regression model for each feature.\n",
    "    \n",
    "    Process:\n",
    "    1. Process 'last_review' to create binary features: 'has_last_review' and 'no_last_review'.\n",
    "    2. Select relevant features and the target variable.\n",
    "    3. Convert categorical variables to dummy variables for regression analysis.\n",
    "    4. Split the dataset into training and testing sets.\n",
    "    5. Train a linear regression model using a pipeline with standard scaling.\n",
    "    6. Visualize the coefficients to interpret feature importance.\n",
    "    7. Evaluate the model using R-squared, Mean Squared Error (MSE), and Cross-Validation.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create binary features for 'last_review'\n",
    "    df['has_last_review'] = df['last_review'].apply(lambda x: 1 if x != 'No reviews' else 0)\n",
    "    df['no_last_review'] = df['last_review'].apply(lambda x: 1 if x == 'No reviews' else 0)\n",
    "    \n",
    "    # Selecting relevant features for the analysis\n",
    "    features = ['room_type', 'neighbourhood', 'minimum_nights', \n",
    "                'number_of_reviews', 'reviews_per_month', 'availability_365',\n",
    "                'has_last_review', 'no_last_review']\n",
    "    target = 'price'\n",
    "    \n",
    "    # Preprocessing: Convert categorical variables to dummy variables\n",
    "    df = pd.get_dummies(df[features + [target]], drop_first=True)\n",
    "    \n",
    "    # Splitting the dataset into training and testing sets\n",
    "    X = df.drop(target, axis=1)\n",
    "    y = df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "    \n",
    "    # Fitting the linear regression model using a pipeline\n",
    "    model = make_pipeline(StandardScaler(), LinearRegression())\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Extracting and sorting the coefficients by absolute value\n",
    "    coefficients = pd.DataFrame(\n",
    "        model.named_steps['linearregression'].coef_, \n",
    "        index=X.columns,  # Set the index to the feature names\n",
    "        columns=['Coefficient']\n",
    "    )\n",
    "    coefficients = coefficients.reindex(coefficients['Coefficient'].abs().sort_values(ascending=False).index)\n",
    "    \n",
    "    # Resetting the index to create a proper DataFrame for plotting\n",
    "    coefficients.reset_index(inplace=True)\n",
    "    coefficients.rename(columns={'index': 'Feature'}, inplace=True)  # Rename the index column for clarity\n",
    "\n",
    "    # Create a new column to categorize coefficients as positive or negative\n",
    "    coefficients['Sign'] = coefficients['Coefficient'].apply(lambda x: 'Positive' if x > 0 else 'Negative')\n",
    "\n",
    "    # Visualizing the coefficients\n",
    "    plot_bar(coefficients, \n",
    "              x='Coefficient', \n",
    "              y='Feature',  # Use the renamed column for y\n",
    "              title='Factors Influencing Airbnb Listing Price', \n",
    "              xlabel='Coefficient Value', \n",
    "              ylabel='Features', \n",
    "              hue='Sign',  # Use hue to color bars based on the sign of the coefficient\n",
    "              rotation=0)\n",
    "    \n",
    "    # Model evaluation\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    print(\"\\nModel Evaluation:\")\n",
    "    print(f\"R-squared: {r2:.2f} - Indicates the proportion of variance explained by the model.\")\n",
    "    print(f\"Mean Squared Error: {mse:.2f} - Measures the average squared difference between predicted and actual values.\")\n",
    "    \n",
    "    # Cross-validation\n",
    "    cross_val_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "    print(f\"Cross-Validated R-squared: {cross_val_scores.mean():.2f} - Average R-squared across 5 folds.\")\n",
    "    \n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.Analyze availability correlation \n",
    "def analyze_availability_correlation(df):\n",
    "    \"\"\"\n",
    "    Analyze and visualize the correlation between availability (availability_365)\n",
    "    and two key features: number of reviews and price.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame containing Airbnb data.\n",
    "    \n",
    "    Returns:\n",
    "    None: Displays scatter plots and correlation values for the analysis.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Correlation values\n",
    "    correlation_reviews = df['availability_365'].corr(df['number_of_reviews'])\n",
    "    correlation_price = df['availability_365'].corr(df['price'])\n",
    "    \n",
    "    print(f\"Correlation between availability and number of reviews: {correlation_reviews:.2f}\")\n",
    "    print(f\"Correlation between availability and price: {correlation_price:.2f}\")\n",
    "    \n",
    "    # Scatter plot: Availability vs. Number of Reviews\n",
    "    plot_scatter('availability_365', 'number_of_reviews', df, \n",
    "                 'Availability vs. Number of Reviews', \n",
    "                 'Availability (days/year)', \n",
    "                 'Number of Reviews', \n",
    "                 hue='room_type')\n",
    "\n",
    "    # Scatter plot: Availability vs. Price\n",
    "    plot_scatter('availability_365', 'price', df, \n",
    "                 'Availability vs. Price', \n",
    "                 'Availability (days/year)', \n",
    "                 'Price ($)', \n",
    "                 hue='room_type')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Analyze location trends \n",
    "def analyze_location_trends(df):\n",
    "    \"\"\"\n",
    "    Analyze location-based trends in reviews, pricing, and popularity.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame containing Airbnb data.\n",
    "\n",
    "    Returns:\n",
    "    None: Displays bar plots and summary statistics highlighting location-based trends.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Group by neighborhood\n",
    "    location_stats = df.groupby('neighbourhood').agg({\n",
    "        'price': 'mean',\n",
    "        'number_of_reviews': 'mean',\n",
    "        'reviews_per_month': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    location_stats.rename(columns={\n",
    "        'price': 'Average Price',\n",
    "        'number_of_reviews': 'Average Number of Reviews',\n",
    "        'reviews_per_month': 'Average Reviews Per Month'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Sort by Average Price for visualization and rounding to 2 decimal places\n",
    "    location_stats = location_stats.sort_values(by='Average Price', ascending=False).round(2)\n",
    "\n",
    "    # Display summary statistics\n",
    "    print(\"Location-Based Trends:\\n\")\n",
    "    print(tabulate(location_stats, headers='keys', tablefmt='pretty'))\n",
    "\n",
    "    # Bar plot: Average Price by Neighborhood\n",
    "    plot_bar(location_stats, \n",
    "              x='neighbourhood', \n",
    "              y='Average Price', \n",
    "              title='Average Price by Neighborhood', \n",
    "              xlabel='Neighborhood', \n",
    "              ylabel='Average Price ($)', \n",
    "              hue='neighbourhood',  # Specify hue for coloring\n",
    "              rotation=45)\n",
    "\n",
    "    # Bar plot: Average Number of Reviews by Neighborhood\n",
    "    plot_bar(location_stats, \n",
    "              x='neighbourhood', \n",
    "              y='Average Number of Reviews', \n",
    "              title='Average Number of Reviews by Neighborhood', \n",
    "              xlabel='Neighborhood', \n",
    "              ylabel='Average Number of Reviews', \n",
    "              hue='neighbourhood',  # Specify hue for coloring\n",
    "              rotation=45)\n",
    "\n",
    "    # Bar plot: Average Reviews Per Month by Neighborhood\n",
    "    plot_bar(location_stats, \n",
    "              x='neighbourhood', \n",
    "              y='Average Reviews Per Month', \n",
    "              title='Average Reviews Per Month by Neighborhood', \n",
    "              xlabel='Neighborhood', \n",
    "              ylabel='Average Reviews Per Month', \n",
    "              hue='neighbourhood',  # Specify hue for coloring\n",
    "              rotation=45)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
