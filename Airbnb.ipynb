{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Write a Data Science Blog Post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "\n",
    "### Business Questions\n",
    "This analysis addresses the following:\n",
    "\n",
    "- What factors most influence the price of an Airbnb listing in Albany?\n",
    "- Is there a correlation between listing price and availability throughout the year? Is there a correlation between the number of reviews and availability?\n",
    "- Are there location-based trends in average price, number of reviews, or review frequency in Albany?\n",
    "- How does the room type affect the average price and availability of listings?\n",
    "- Do listings with more frequent reviews tend to have higher/lower prices or higher/lower availability?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Gather\n",
    "The first step in any data science project is to gather the data. For this project, we will load the dataset using a custom function with robust error handling to ensure smooth operation even if issues arise with the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data from listings.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tabulate import tabulate\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# 1. Load Data Function\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load a CSV file into a DataFrame with error handling.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): Path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Loaded DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Successfully loaded data from {file_path}\\n\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Error: The file {file_path} was not found.\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        raise ValueError(\"Error: The file is empty.\")\n",
    "    except pd.errors.ParserError:\n",
    "        raise ValueError(\"Error: The file could not be parsed.\")\n",
    "\n",
    "# Opening data file \n",
    "file_path = 'listings.csv'\n",
    "\n",
    "try:\n",
    "    # Step-by-step execution of the data pipeline\n",
    "    df = load_data(file_path)                   # Load data\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Assess and Analyze\n",
    "In Assess step, we will assess the dataset for potential issues such as missing values, incorrect data types, and duplicate rows. This will guide the cleaning process.\n",
    "\n",
    "Then Analyze step focuses on exploring the data to uncover trends, correlations, and other insights that can inform the modeling process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are there any missing values or unusual patterns in the dataset?  \n",
    "To build reliable models and gain insights, it's essential to understand the data quality.  \n",
    "- We explore missing values, data types, and summary statistics.  \n",
    "- This step helps identify potential data cleaning needs and unusual trends that may affect further analysis.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Assess Step: Dataset Overview ---\n",
      "\n",
      "Number of rows: 426\n",
      "Number of columns: 18\n",
      "\n",
      "--- Missing Data Information ---\n",
      "Number of columns with missing data: 5\n",
      "+--------------------------------+---------------+--------------------+\n",
      "|                                | Missing Count | Missing Percentage |\n",
      "+--------------------------------+---------------+--------------------+\n",
      "|               id               |      0.0      |        0.0         |\n",
      "|              name              |      0.0      |        0.0         |\n",
      "|            host_id             |      0.0      |        0.0         |\n",
      "|           host_name            |      0.0      |        0.0         |\n",
      "|      neighbourhood_group       |     426.0     |       100.0        |\n",
      "|         neighbourhood          |      0.0      |        0.0         |\n",
      "|            latitude            |      0.0      |        0.0         |\n",
      "|           longitude            |      0.0      |        0.0         |\n",
      "|           room_type            |      0.0      |        0.0         |\n",
      "|             price              |     26.0      |        6.1         |\n",
      "|         minimum_nights         |      0.0      |        0.0         |\n",
      "|       number_of_reviews        |      0.0      |        0.0         |\n",
      "|          last_review           |     60.0      |       14.08        |\n",
      "|       reviews_per_month        |     60.0      |       14.08        |\n",
      "| calculated_host_listings_count |      0.0      |        0.0         |\n",
      "|        availability_365        |      0.0      |        0.0         |\n",
      "|     number_of_reviews_ltm      |      0.0      |        0.0         |\n",
      "|            license             |     426.0     |       100.0        |\n",
      "+--------------------------------+---------------+--------------------+\n",
      "\n",
      "--- Data Types ---\n",
      "+----+--------------------------------+-----------+\n",
      "|    |             Column             | Data Type |\n",
      "+----+--------------------------------+-----------+\n",
      "| 0  |               id               |   int64   |\n",
      "| 1  |              name              |  object   |\n",
      "| 2  |            host_id             |   int64   |\n",
      "| 3  |           host_name            |  object   |\n",
      "| 4  |      neighbourhood_group       |  float64  |\n",
      "| 5  |         neighbourhood          |  object   |\n",
      "| 6  |            latitude            |  float64  |\n",
      "| 7  |           longitude            |  float64  |\n",
      "| 8  |           room_type            |  object   |\n",
      "| 9  |             price              |  float64  |\n",
      "| 10 |         minimum_nights         |   int64   |\n",
      "| 11 |       number_of_reviews        |   int64   |\n",
      "| 12 |          last_review           |  object   |\n",
      "| 13 |       reviews_per_month        |  float64  |\n",
      "| 14 | calculated_host_listings_count |   int64   |\n",
      "| 15 |        availability_365        |   int64   |\n",
      "| 16 |     number_of_reviews_ltm      |   int64   |\n",
      "| 17 |            license             |  float64  |\n",
      "+----+--------------------------------+-----------+\n",
      "\n",
      "Number of duplicate rows: 0\n",
      "\n",
      "--- Unique Values per Column ---\n",
      "+----+--------------------------------+---------------+\n",
      "|    |             Column             | Unique Values |\n",
      "+----+--------------------------------+---------------+\n",
      "| 0  |               id               |      426      |\n",
      "| 1  |              name              |      424      |\n",
      "| 2  |            host_id             |      191      |\n",
      "| 3  |           host_name            |      170      |\n",
      "| 4  |      neighbourhood_group       |       0       |\n",
      "| 5  |         neighbourhood          |      15       |\n",
      "| 6  |            latitude            |      408      |\n",
      "| 7  |           longitude            |      413      |\n",
      "| 8  |           room_type            |       3       |\n",
      "| 9  |             price              |      154      |\n",
      "| 10 |         minimum_nights         |      22       |\n",
      "| 11 |       number_of_reviews        |      140      |\n",
      "| 12 |          last_review           |      131      |\n",
      "| 13 |       reviews_per_month        |      257      |\n",
      "| 14 | calculated_host_listings_count |      13       |\n",
      "| 15 |        availability_365        |      200      |\n",
      "| 16 |     number_of_reviews_ltm      |      75       |\n",
      "| 17 |            license             |       0       |\n",
      "+----+--------------------------------+---------------+\n",
      "\n",
      "--- Analyze Step: Exploring Data ---\n",
      "\n",
      "\n",
      "--- Numerical Data Summary ---\n",
      "+-------+------------------------+--------------+---------------------+----------+-----------+--------+----------------+-------------------+-------------------+--------------------------------+------------------+-----------------------+---------+\n",
      "|       |           id           |   host_id    | neighbourhood_group | latitude | longitude | price  | minimum_nights | number_of_reviews | reviews_per_month | calculated_host_listings_count | availability_365 | number_of_reviews_ltm | license |\n",
      "+-------+------------------------+--------------+---------------------+----------+-----------+--------+----------------+-------------------+-------------------+--------------------------------+------------------+-----------------------+---------+\n",
      "| count |         426.0          |    426.0     |         0.0         |  426.0   |   426.0   | 400.0  |     426.0      |       426.0       |       366.0       |             426.0              |      426.0       |         426.0         |   0.0   |\n",
      "| mean  | 6.048428857879354e+17  | 222616893.76 |         nan         |  42.66   |  -73.78   | 128.48 |      6.31      |       58.1        |       2.15        |              5.69              |      221.12      |         16.01         |   nan   |\n",
      "|  std  | 4.706590222822843e+17  | 184910311.19 |         nan         |   0.01   |   0.02    | 125.5  |     21.86      |      104.45       |       2.11        |              6.24              |      120.48      |         22.19         |   nan   |\n",
      "|  min  |       2992450.0        |   649068.0   |         nan         |  42.63   |  -73.88   |  24.0  |      1.0       |        0.0        |       0.03        |              1.0               |       0.0        |          0.0          |   nan   |\n",
      "|  25%  |       50247054.5       |  47625981.0  |         nan         |  42.65   |  -73.79   | 77.75  |      1.0       |        4.0        |       0.57        |              1.0               |      91.25       |          1.0          |   nan   |\n",
      "|  50%  | 7.545449678012308e+17  | 185594343.0  |         nan         |  42.66   |  -73.77   | 104.0  |      2.0       |       18.0        |       1.45        |              3.0               |      246.0       |          6.0          |   nan   |\n",
      "|  75%  | 1.0144694217509396e+18 | 382970529.0  |         nan         |  42.66   |  -73.76   | 139.0  |      3.0       |       64.0        |       3.04        |              8.0               |      339.0       |         22.0          |   nan   |\n",
      "|  max  | 1.2379636689127977e+18 | 580892646.0  |         nan         |  42.71   |  -73.74   | 1750.0 |     365.0      |       853.0       |       11.22       |              25.0              |      365.0       |         144.0         |   nan   |\n",
      "+-------+------------------------+--------------+---------------------+----------+-----------+--------+----------------+-------------------+-------------------+--------------------------------+------------------+-----------------------+---------+\n",
      "\n",
      "--- Categorical Data Summary ---\n",
      "+---------------+-------+--------+-----------------------------------------------+------+----------------+\n",
      "|               | count | unique |                      top                      | freq | Distinct Count |\n",
      "+---------------+-------+--------+-----------------------------------------------+------+----------------+\n",
      "|     name      |  426  |  424   | Cozy 3rd Floor Room in Historic Manor Retreat |  2   |      424       |\n",
      "|   host_name   |  426  |  170   |                     Diana                     |  27  |      170       |\n",
      "| neighbourhood |  426  |   15   |                  SIXTH WARD                   |  97  |       15       |\n",
      "|   room_type   |  426  |   3    |                Entire home/apt                | 310  |       3        |\n",
      "|  last_review  |  366  |  131   |                  2024-09-02                   |  20  |      131       |\n",
      "+---------------+-------+--------+-----------------------------------------------+------+----------------+\n",
      "\n",
      "--- Correlation Matrix ---\n",
      "+--------------------------------+--------+-----------+-----------------------+------------+-------------+---------+------------------+---------------------+---------------------+----------------------------------+--------------------+-------------------------+-----------+\n",
      "|                                |     id |   host_id |   neighbourhood_group |   latitude |   longitude |   price |   minimum_nights |   number_of_reviews |   reviews_per_month |   calculated_host_listings_count |   availability_365 |   number_of_reviews_ltm |   license |\n",
      "|--------------------------------+--------+-----------+-----------------------+------------+-------------+---------+------------------+---------------------+---------------------+----------------------------------+--------------------+-------------------------+-----------|\n",
      "| id                             |   1    |      0.32 |                   nan |       0.07 |       -0.02 |   -0.01 |            -0    |               -0.49 |               -0.03 |                            -0    |              -0.16 |                   -0.21 |       nan |\n",
      "| host_id                        |   0.32 |      1    |                   nan |      -0.01 |        0.02 |    0.02 |             0.06 |               -0.23 |               -0.03 |                            -0.03 |              -0.05 |                   -0.12 |       nan |\n",
      "| neighbourhood_group            | nan    |    nan    |                   nan |     nan    |      nan    |  nan    |           nan    |              nan    |              nan    |                           nan    |             nan    |                  nan    |       nan |\n",
      "| latitude                       |   0.07 |     -0.01 |                   nan |       1    |       -0.57 |    0.06 |            -0.01 |               -0.14 |               -0.1  |                            -0.02 |               0.09 |                   -0.1  |       nan |\n",
      "| longitude                      |  -0.02 |      0.02 |                   nan |      -0.57 |        1    |   -0.17 |             0.05 |                0.06 |                0.02 |                             0.02 |              -0.05 |                   -0.03 |       nan |\n",
      "| price                          |  -0.01 |      0.02 |                   nan |       0.06 |       -0.17 |    1    |            -0.06 |               -0.07 |               -0.07 |                             0.09 |               0    |                   -0.05 |       nan |\n",
      "| minimum_nights                 |  -0    |      0.06 |                   nan |      -0.01 |        0.05 |   -0.06 |             1    |               -0.1  |               -0.12 |                            -0.07 |               0.05 |                   -0.15 |       nan |\n",
      "| number_of_reviews              |  -0.49 |     -0.23 |                   nan |      -0.14 |        0.06 |   -0.07 |            -0.1  |                1    |                0.66 |                            -0.02 |              -0.02 |                    0.69 |       nan |\n",
      "| reviews_per_month              |  -0.03 |     -0.03 |                   nan |      -0.1  |        0.02 |   -0.07 |            -0.12 |                0.66 |                1    |                             0.01 |              -0.09 |                    0.84 |       nan |\n",
      "| calculated_host_listings_count |  -0    |     -0.03 |                   nan |      -0.02 |        0.02 |    0.09 |            -0.07 |               -0.02 |                0.01 |                             1    |              -0.02 |                    0.03 |       nan |\n",
      "| availability_365               |  -0.16 |     -0.05 |                   nan |       0.09 |       -0.05 |    0    |             0.05 |               -0.02 |               -0.09 |                            -0.02 |               1    |                   -0.06 |       nan |\n",
      "| number_of_reviews_ltm          |  -0.21 |     -0.12 |                   nan |      -0.1  |       -0.03 |   -0.05 |            -0.15 |                0.69 |                0.84 |                             0.03 |              -0.06 |                    1    |       nan |\n",
      "| license                        | nan    |    nan    |                   nan |     nan    |      nan    |  nan    |           nan    |              nan    |              nan    |                           nan    |             nan    |                  nan    |       nan |\n",
      "+--------------------------------+--------+-----------+-----------------------+------------+-------------+---------+------------------+---------------------+---------------------+----------------------------------+--------------------+-------------------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "def display_data_info(df):\n",
    "    \"\"\"\n",
    "    Assess and analyze the DataFrame.\n",
    "\n",
    "    Steps:\n",
    "    1. **Assess Step**:\n",
    "        - Overview of the dataset: Number of rows and columns.\n",
    "        - Missing data: Count and percentage of missing values in each column.\n",
    "        - Data types: Types of data in each column.\n",
    "        - Duplicate rows: Number of duplicate rows.\n",
    "        - Unique values: Count of unique values for each column.\n",
    "\n",
    "    2. **Analyze Step**:\n",
    "        - Numerical data summary: Descriptive statistics for numerical columns.\n",
    "        - Categorical data summary: Descriptive statistics for categorical columns.\n",
    "        - Correlation matrix: Correlation between numerical columns.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Outputs:\n",
    "    Prints a detailed assessment and analysis of the dataset, including:\n",
    "    - Missing data information.\n",
    "    - Data type details.\n",
    "    - Summary statistics for numerical and categorical columns.\n",
    "    - Unique values per column.\n",
    "    - Correlation matrix for numerical data.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Assess Step: Dataset Overview ---\\n\")\n",
    "    print(f\"Number of rows: {df.shape[0]}\")\n",
    "    print(f\"Number of columns: {df.shape[1]}\")\n",
    "\n",
    "    # Missing Data Information\n",
    "    print(\"\\n--- Missing Data Information ---\")\n",
    "    missing_counts = df.isna().sum()\n",
    "    num_cols_missing = (missing_counts > 0).sum()\n",
    "    print(f\"Number of columns with missing data: {num_cols_missing}\")\n",
    "\n",
    "    if num_cols_missing > 0:  # Only show details if there are any missing values.\n",
    "        missing_percentage = (missing_counts / len(df)) * 100\n",
    "        missing_info = pd.DataFrame({\n",
    "            'Missing Count': missing_counts,\n",
    "            'Missing Percentage': missing_percentage\n",
    "        }).round(2)\n",
    "        print(tabulate(\n",
    "            missing_info,\n",
    "            headers='keys',\n",
    "            tablefmt='pretty',\n",
    "            showindex=True\n",
    "        ))  # Show index (column names)\n",
    "\n",
    "    # Data Type Information\n",
    "    print(\"\\n--- Data Types ---\")\n",
    "    print(tabulate(\n",
    "        df.dtypes.reset_index(),\n",
    "        headers=['Column', 'Data Type'],\n",
    "        tablefmt='pretty'\n",
    "    ))\n",
    "\n",
    "    # Duplicate Rows\n",
    "    duplicate_count = df.duplicated().sum()\n",
    "    print(f\"\\nNumber of duplicate rows: {duplicate_count}\")\n",
    "\n",
    "    # Unique Values\n",
    "    print(\"\\n--- Unique Values per Column ---\")\n",
    "    print(tabulate(\n",
    "        df.nunique().reset_index(),\n",
    "        headers=['Column', 'Unique Values'],\n",
    "        tablefmt='pretty'\n",
    "    ))\n",
    "\n",
    "    print(\"\\n--- Analyze Step: Exploring Data ---\\n\")\n",
    "\n",
    "    # Summary Statistics (Numerical Data)\n",
    "    print(\"\\n--- Numerical Data Summary ---\")\n",
    "    numerical_summary = df.describe(include=np.number).round(2)\n",
    "    print(tabulate(numerical_summary, headers='keys', tablefmt='pretty'))\n",
    "\n",
    "    # Summary Statistics (Categorical Data)\n",
    "    print(\"\\n--- Categorical Data Summary ---\")\n",
    "    # Handles both object and category dtypes\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "    if categorical_cols.size > 0:\n",
    "        categorical_summary = df[categorical_cols].describe().T\n",
    "        # Adds distinct count, handles missing values better.\n",
    "        categorical_summary['Distinct Count'] = df[categorical_cols].nunique()\n",
    "        print(tabulate(categorical_summary, headers='keys', tablefmt='pretty'))\n",
    "    else:\n",
    "        print(\"No categorical data found.\")\n",
    "\n",
    "    # Correlation Matrix (Numerical Data)\n",
    "    print(\"\\n--- Correlation Matrix ---\")\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    if numeric_df.shape[1] > 1:\n",
    "        correlation_matrix = numeric_df.corr().round(2)\n",
    "        print(tabulate(\n",
    "            correlation_matrix,\n",
    "            headers='keys',\n",
    "            tablefmt='psql'\n",
    "        ))  # 'psql' is visually nicer for matrices\n",
    "    else:\n",
    "        print(\"Not enough numerical columns to compute correlation matrix.\")\n",
    "\n",
    "\n",
    "display_data_info(df)                         # Assess and analyze data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Cleaning\n",
    "The cleaning process involves handling missing values, correcting data types, and removing duplicates or irrelevant columns. The goal is to prepare a clean dataset for analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A- Can we clean the data to improve its usability?  \n",
    "Cleaning the data ensures that:  \n",
    "- Irrelevant or problematic columns are removed.  \n",
    "- Data anomalies are corrected.  \n",
    "This step prepares the dataset for effective analysis and modeling.  \n",
    "\n",
    "### Justification for Cleaning the Dataset\n",
    "The dataset was cleaned to remove unnecessary columns and handle missing values in specific features:  \n",
    "\n",
    "1. **Removing Columns with 100% Missing Values**  \n",
    "   - **Rationale:** Columns with all missing values provide no useful information for analysis or modeling. Dropping such columns simplifies the dataset without any loss of valuable data.  \n",
    "\n",
    "2. **'last_review' Column**  \n",
    "   - **Handling Missing Values:**  \n",
    "     - Missing values were replaced with the placeholder value `'No reviews'`.  \n",
    "     - **Rationale:** This ensures that the column is still usable for analysis while clearly indicating the absence of review data for certain entries.  \n",
    "\n",
    "   - **Data Type Conversion:**  \n",
    "     - Converted to a `datetime` type to facilitate temporal analysis.  \n",
    "     - **Rationale:** This conversion allows for trend analysis over time, such as understanding the distribution of recent reviews or seasonal patterns in listings.  \n",
    "\n",
    "These steps ensure the dataset is clean, consistent, and ready for analysis while retaining as much information as possible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of columns: 18\n",
      "2 columns removed containing 100% missing values.\n",
      "'last_review' column converted to datetime and missing values filled with 'No reviews'.\n"
     ]
    }
   ],
   "source": [
    "# 3. Clean Data Function\n",
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "    Clean the dataset by removing empty columns, preprocessing 'last_review', and\n",
    "    printing informative messages on the cleaning steps taken.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input DataFrame to clean.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Cleaned DataFrame with:\n",
    "        - Columns with 100% missing values removed.\n",
    "        - 'last_review' column converted to datetime and missing values imputed\n",
    "          with 'No reviews' placeholder.\n",
    "    \"\"\"\n",
    "\n",
    "    # Print the original number of columns for reference\n",
    "    original_num_cols = len(df.columns)\n",
    "    print(f\"Original number of columns: {original_num_cols}\")\n",
    "\n",
    "    # Remove columns with 100% missing values\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "\n",
    "    # Print the number of columns removed, if any\n",
    "    num_cols_removed = original_num_cols - len(df.columns)\n",
    "    if num_cols_removed > 0:\n",
    "        print(f\"{num_cols_removed} columns removed containing 100% missing values.\")\n",
    "\n",
    "    # Handle 'last_review': Convert to datetime and fill missing with placeholder\n",
    "    df.loc[:, 'last_review'] = pd.to_datetime(\n",
    "        df['last_review'], errors='coerce').dt.date\n",
    "    df.loc[:, 'last_review'] = df['last_review'].fillna('No reviews')\n",
    "\n",
    "    # Print information about handling the 'last_review' column\n",
    "    print(f\"'last_review' column converted to datetime and missing values filled with 'No reviews'.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = clean_data(df)                           # Clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B- How can missing values be handled effectively?  \n",
    "Missing values can distort analysis and modeling.  \n",
    "- We explore imputation strategies to handle missing values systematically.  \n",
    "\n",
    "### Justification for Imputing Missing Values\n",
    "For this project, missing values were imputed based on the following rationale:\n",
    "\n",
    "1. **'reviews_per_month' Column**  \n",
    "   - Chosen Method: **Median Imputation**  \n",
    "   - **Rationale:** The median is robust to outliers, making it a reliable measure of central tendency for imputation. Since reviews per month is a numerical value, imputing missing entries with the median minimizes distortions in the data caused by extreme values or uneven distributions.  \n",
    "\n",
    "2. **'price' Column**  \n",
    "   - Chosen Method: **Median Imputation**  \n",
    "   - **Rationale:** Like reviews per month, the price data might contain outliers (e.g., luxury listings with very high prices). Using the median ensures that these extreme values do not overly influence the imputed data.  \n",
    "\n",
    "By imputing these values instead of removing rows with missing data, we preserve valuable information about the dataset, especially for other features, ensuring better analysis and model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values before imputation: 86\n",
      "Number of missing values after imputation: 0\n",
      "86 missing values imputed.\n"
     ]
    }
   ],
   "source": [
    "# 4. Impute Missing Values\n",
    "def impute_missing_values(df):\n",
    "    \"\"\"\n",
    "    Imputes missing values for numerical columns.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The DataFrame with imputed values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Print the number of missing values before imputation\n",
    "    num_missing_before = df.isnull().sum().sum()\n",
    "    print(f\"Number of missing values before imputation: {num_missing_before}\")\n",
    "\n",
    "    # Impute 'reviews_per_month' and 'price' with the median\n",
    "    # Rationale: The median is robust to outliers and provides a central value for imputation.\n",
    "    df['reviews_per_month'] = df['reviews_per_month'].fillna(\n",
    "        df['reviews_per_month'].median())\n",
    "    df['price'] = df['price'].fillna(df['price'].median())\n",
    "\n",
    "    # Print the number of missing values after imputation\n",
    "    num_missing_after = df.isnull().sum().sum()\n",
    "    print(f\"Number of missing values after imputation: {num_missing_after}\")\n",
    "\n",
    "    # Print the number of missing values imputed\n",
    "    num_missing_imputed = num_missing_before - num_missing_after\n",
    "    print(f\"{num_missing_imputed} missing values imputed.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = impute_missing_values(df)               # Handle missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- Display:\n",
    "DataFrame Exploration in Manageable Chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is there a way to explore large dataframes efficiently?  \n",
    "For large datasets, breaking them into smaller, manageable chunks allows for:  \n",
    "- Easier visual inspection of rows and columns.  \n",
    "- Better understanding of raw data content and structure.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.Display DataFrame in chunks of rows and columns\n",
    "def display_dataframe_in_chunks(df):\n",
    "    \"\"\"\n",
    "    Display the DataFrame in chunks of rows and columns, with user customization.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to display.\n",
    "\n",
    "    Behavior:\n",
    "    - Allows users to specify the number of rows and columns to display interactively.\n",
    "    - Displays the specified number of rows and columns at a time.\n",
    "    - Prompts the user to continue viewing the next chunk of rows and columns.\n",
    "    \"\"\"\n",
    "\n",
    "    num_rows, num_cols = df.shape  # Get the number of rows and columns\n",
    "\n",
    "    # Prompt user for chunk size\n",
    "    while True:\n",
    "        try:\n",
    "            chunk_size = input(f\"Enter the number of rows to display per chunk (default is 10, total rows: {\n",
    "                               num_rows},total columns: {num_cols}): \").strip()\n",
    "            # Default to 10 if input is empty\n",
    "            chunk_size = int(chunk_size) if chunk_size else 10\n",
    "\n",
    "            if chunk_size <= 0:\n",
    "                print(\"Chunk size must be a positive integer. Please try again.\")\n",
    "                continue\n",
    "            break  # Exit input loop if successful\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a valid integer.\")\n",
    "\n",
    "    for i in range(0, len(df), chunk_size):\n",
    "        chunk = df[i:i + chunk_size]\n",
    "        print(tabulate(chunk, headers='keys', tablefmt='pretty'))\n",
    "\n",
    "        if i + chunk_size < len(df):\n",
    "            if input(\"Display next chunk? (yes/no): \").strip().lower() != 'yes':\n",
    "                break\n",
    "\n",
    "    print(\"End of DataFrame reached.\")\n",
    "\n",
    "\n",
    "# Explore data in manageable chunks\n",
    "display_dataframe_in_chunks(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5- Visualize\n",
    "Visualizations help communicate insights effectively. Here, we'll create histograms, scatterplots, and correlation heatmaps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  What do the distributions of numerical features reveal?  \n",
    "Visualizing the distributions of numerical columns can help identify:  \n",
    "- Skewness or normality in the data.  \n",
    "- Outliers or extreme values that may need treatment.  \n",
    "- Trends or relationships that could guide feature engineering or analysis.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Plot Numerical Histograms\n",
    "def plot_numerical_histograms(df):\n",
    "    \"\"\"Plots histograms for numerical columns, skipping empty ones.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    # Select numerical types\n",
    "    numerical_cols = df.select_dtypes(include=np.number)\n",
    "\n",
    "    cols_to_plot = []  # Keep track of numerical and non-empty columns.\n",
    "    for col in numerical_cols:\n",
    "        if not pd.isna(df[col]).all():  # Check if not all values are NaN\n",
    "            cols_to_plot.append(col)\n",
    "\n",
    "    if not cols_to_plot:  # If there are no numerical columns to plot, return a message.\n",
    "        print(\"No numerical columns to plot in DataFrame.\")\n",
    "        return\n",
    "\n",
    "    num_cols = len(cols_to_plot)  # Only includes non-empty columns.\n",
    "    num_rows = (num_cols + 2) // 3  # Correct the number of rows to display.\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=num_rows, ncols=3, figsize=(12, 8))\n",
    "    axes = axes.ravel()  # Flatten axes array for iteration.\n",
    "\n",
    "    for i, col in enumerate(cols_to_plot):  # Only iterate through non-empty cols\n",
    "        ax = axes[i]\n",
    "        sns.histplot(df[col], bins=30, kde=True, ax=ax)\n",
    "        ax.set_title(col)\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # Turn off any extra axes if the number of plots is not a multiple of 3\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_numerical_histograms(df)                 # Visualize numerical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is there a relationship between two numerical variables?  \n",
    "Scatter plots help visualize relationships between numerical features.  \n",
    "- This analysis can reveal linear or non-linear trends, clusters, or outliers.  \n",
    "- It aids in understanding whether further statistical modeling, like regression, is appropriate.  \n",
    "\n",
    "In this step, we use scatter plots to explore and interpret such relationships.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Function for Scatter Plot\n",
    "def plot_scatter(x, y, data, title, xlabel, ylabel, hue=None):\n",
    "    \"\"\"\n",
    "    Helper function to create scatter plots.\n",
    "\n",
    "    Parameters:\n",
    "    x (str): Column name for x-axis.\n",
    "    y (str): Column name for y-axis.\n",
    "    data (pd.DataFrame): DataFrame containing the data.\n",
    "    title (str): Title of the plot.\n",
    "    xlabel (str): Label for x-axis.\n",
    "    ylabel (str): Label for y-axis.\n",
    "    hue (str, optional): Column name for color coding.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.scatterplot(x=x, y=y, data=data, alpha=0.6, hue=hue, palette='cool')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    if hue:\n",
    "        plt.legend(title=hue, loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do categories compare across a numerical variable?  \n",
    "Bar plots provide insights into the distribution of a numerical variable across categories.  \n",
    "- This can highlight differences in averages, sums, or counts across groups.  \n",
    "- It helps identify trends and patterns that inform further analysis or decision-making.  \n",
    "\n",
    "We use this step to compare categories effectively and uncover key trends.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Function for Bar Plot\n",
    "def plot_bar(data, x, y, hue=None, title='', xlabel='', ylabel='', rotation=0):\n",
    "    \"\"\"\n",
    "    Helper function to create bar plots.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): DataFrame containing the data.\n",
    "    x (str): Column name for x-axis.\n",
    "    y (str): Column name for y-axis.\n",
    "    hue (str, optional): Column name for hue (categorical variable).\n",
    "    title (str): Title of the plot.\n",
    "    xlabel (str): Label for x-axis.\n",
    "    ylabel (str): Label for y-axis.\n",
    "    rotation (int, optional): Rotation angle for x-tick labels.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # If hue is provided, use it for coloring\n",
    "    if hue:\n",
    "        sns.barplot(data=data, x=x, y=y, hue=hue, palette='cool')\n",
    "    else:\n",
    "        # Use default colors if no hue is provided\n",
    "        sns.barplot(data=data, x=x, y=y)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xticks(rotation=rotation, ha='right')\n",
    "\n",
    "    # Check if hue is provided and has unique values for legend\n",
    "    if hue:  # Improved legend handling\n",
    "        handles, labels = plt.gca().get_legend_handles_labels()\n",
    "        if handles:  # Check if any handles/labels exist.\n",
    "            plt.legend(handles, labels, title=hue, loc='best')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6- Data Modeling\n",
    "Here, we will build a simple linear regression model to predict Airbnb prices based on selected features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What factors most influence the price of an Airbnb listing in Albany? \n",
    "Pricing is a critical factor for both hosts and guests. Understanding the drivers of price can:  \n",
    "- Help identify key features that impact revenue.  \n",
    "- Provide insights for optimizing listing prices.  \n",
    "\n",
    "In this step, we analyze various factors, such as location, room type, and availability, to understand their influence on pricing. This involves exploring correlations, running statistical tests, and using regression models to quantify the relationships.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Analyze price factors\n",
    "def analyze_airbnb_price_factors(df):\n",
    "    \"\"\"\n",
    "    Analyze the factors influencing Airbnb listing prices using linear regression.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The preprocessed DataFrame containing Airbnb data.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing the coefficients of the linear regression model for each feature.\n",
    "\n",
    "    Process:\n",
    "    1. Process 'last_review' to create binary features: 'has_last_review' and 'no_last_review'.\n",
    "    2. Select relevant features and the target variable.\n",
    "    3. Convert categorical variables to dummy variables for regression analysis.\n",
    "    4. Split the dataset into training and testing sets.\n",
    "    5. Train a linear regression model using a pipeline with standard scaling.\n",
    "    6. Visualize the coefficients to interpret feature importance.\n",
    "    7. Evaluate the model using R-squared, Mean Squared Error (MSE), and Cross-Validation.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create binary features for 'last_review'\n",
    "    df['has_last_review'] = df['last_review'].apply(\n",
    "        lambda x: 1 if x != 'No reviews' else 0)\n",
    "    df['no_last_review'] = df['last_review'].apply(\n",
    "        lambda x: 1 if x == 'No reviews' else 0)\n",
    "\n",
    "    # Selecting relevant features for the analysis\n",
    "    features = ['room_type', 'neighbourhood', 'minimum_nights',\n",
    "                'number_of_reviews', 'reviews_per_month', 'availability_365',\n",
    "                'has_last_review', 'no_last_review']\n",
    "    target = 'price'\n",
    "\n",
    "    # Preprocessing: Convert categorical variables to dummy variables\n",
    "    df = pd.get_dummies(df[features + [target]], drop_first=True)\n",
    "\n",
    "    # Splitting the dataset into training and testing sets\n",
    "    X = df.drop(target, axis=1)\n",
    "    y = df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "    # Fitting the linear regression model using a pipeline\n",
    "    model = make_pipeline(StandardScaler(), LinearRegression())\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Extracting and sorting the coefficients by absolute value\n",
    "    coefficients = pd.DataFrame(\n",
    "        model.named_steps['linearregression'].coef_,\n",
    "        index=X.columns,  # Set the index to the feature names\n",
    "        columns=['Coefficient']\n",
    "    )\n",
    "    coefficients = coefficients.reindex(\n",
    "        coefficients['Coefficient'].abs().sort_values(ascending=False).index)\n",
    "\n",
    "    # Resetting the index to create a proper DataFrame for plotting\n",
    "    coefficients.reset_index(inplace=True)\n",
    "    # Rename the index column for clarity\n",
    "    coefficients.rename(columns={'index': 'Feature'}, inplace=True)\n",
    "\n",
    "    # Create a new column to categorize coefficients as positive or negative\n",
    "    coefficients['Sign'] = coefficients['Coefficient'].apply(\n",
    "        lambda x: 'Positive' if x > 0 else 'Negative')\n",
    "\n",
    "    # Visualizing the coefficients\n",
    "    plot_bar(coefficients,\n",
    "             x='Coefficient',\n",
    "             y='Feature',  # Use the renamed column for y\n",
    "             title='Factors Influencing Airbnb Listing Price',\n",
    "             xlabel='Coefficient Value',\n",
    "             ylabel='Features',\n",
    "             hue='Sign',  # Use hue to color bars based on the sign of the coefficient\n",
    "             rotation=0)\n",
    "\n",
    "    # Model evaluation\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    print(\"\\nModel Evaluation:\")\n",
    "    print(\n",
    "        f\"R-squared: {r2:.2f} - Indicates the proportion of variance explained by the model.\")\n",
    "    print(f\"Mean Squared Error: {\n",
    "          mse:.2f} - Measures the average squared difference between predicted and actual values.\")\n",
    "\n",
    "    # Cross-validation\n",
    "    cross_val_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "    print(f\"Cross-Validated R-squared: {cross_val_scores.mean()          :.2f} - Average R-squared across 5 folds.\")\n",
    "\n",
    "    return coefficients\n",
    "\n",
    "\n",
    "analyze_airbnb_price_factors(df)             # Analyze price factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Is there a correlation between listing price and availability throughout the year?\n",
    "### - Is there a correlation between the number of reviews and availability?\n",
    " \n",
    "Understanding the correlation between availability and other variables can:  \n",
    "- Reveal patterns in booking behavior.  \n",
    "- Provide insights into seasonality or high-demand periods.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.Analyze availability correlation\n",
    "def analyze_availability_correlation(df):\n",
    "    \"\"\"\n",
    "    Analyze and visualize the correlation between availability (availability_365)\n",
    "    and two key features: number of reviews and price.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame containing Airbnb data.\n",
    "\n",
    "    Returns:\n",
    "    None: Displays scatter plots and correlation values for the analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    # Correlation values\n",
    "    correlation_reviews = df['availability_365'].corr(df['number_of_reviews'])\n",
    "    correlation_price = df['availability_365'].corr(df['price'])\n",
    "\n",
    "    print(f\"Correlation between availability and number of reviews: {\n",
    "          correlation_reviews:.2f}\")\n",
    "    print(f\"Correlation between availability and price: {\n",
    "          correlation_price:.2f}\")\n",
    "\n",
    "    # Scatter plot: Availability vs. Number of Reviews\n",
    "    plot_scatter('availability_365', 'number_of_reviews', df,\n",
    "                 'Availability vs. Number of Reviews',\n",
    "                 'Availability (days/year)',\n",
    "                 'Number of Reviews',\n",
    "                 hue='room_type')\n",
    "\n",
    "    # Scatter plot: Availability vs. Price\n",
    "    plot_scatter('availability_365', 'price', df,\n",
    "                 'Availability vs. Price',\n",
    "                 'Availability (days/year)',\n",
    "                 'Price ($)',\n",
    "                 hue='room_type')\n",
    "\n",
    "\n",
    "# Analyze correlations in availability\n",
    "analyze_availability_correlation(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are there location-based trends in average price, number of reviews, or review frequency in Albany?\n",
    "  \n",
    "Location often plays a critical role in listing popularity.  \n",
    "- We analyze geospatial patterns and distribution of listings by neighborhood or area.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Analyze location trends\n",
    "def analyze_location_trends(df):\n",
    "    \"\"\"\n",
    "    Analyze location-based trends in reviews, pricing, and popularity.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame containing Airbnb data.\n",
    "\n",
    "    Returns:\n",
    "    None: Displays bar plots and summary statistics highlighting location-based trends.\n",
    "    \"\"\"\n",
    "\n",
    "    # Group by neighborhood\n",
    "    location_stats = df.groupby('neighbourhood').agg({\n",
    "        'price': 'mean',\n",
    "        'number_of_reviews': 'mean',\n",
    "        'reviews_per_month': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    location_stats.rename(columns={\n",
    "        'price': 'Average Price',\n",
    "        'number_of_reviews': 'Average Number of Reviews',\n",
    "        'reviews_per_month': 'Average Reviews Per Month'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Sort by Average Price for visualization and rounding to 2 decimal places\n",
    "    location_stats = location_stats.sort_values(\n",
    "        by='Average Price', ascending=False).round(2)\n",
    "\n",
    "    # Display summary statistics\n",
    "    print(\"Location-Based Trends:\\n\")\n",
    "    print(tabulate(location_stats, headers='keys', tablefmt='pretty'))\n",
    "\n",
    "    # Bar plot: Average Price by Neighborhood\n",
    "    plot_bar(location_stats,\n",
    "             x='neighbourhood',\n",
    "             y='Average Price',\n",
    "             title='Average Price by Neighborhood',\n",
    "             xlabel='Neighborhood',\n",
    "             ylabel='Average Price ($)',\n",
    "             hue='neighbourhood',  # Specify hue for coloring\n",
    "             rotation=45)\n",
    "\n",
    "    # Bar plot: Average Number of Reviews by Neighborhood\n",
    "    plot_bar(location_stats,\n",
    "             x='neighbourhood',\n",
    "             y='Average Number of Reviews',\n",
    "             title='Average Number of Reviews by Neighborhood',\n",
    "             xlabel='Neighborhood',\n",
    "             ylabel='Average Number of Reviews',\n",
    "             hue='neighbourhood',  # Specify hue for coloring\n",
    "             rotation=45)\n",
    "\n",
    "    # Bar plot: Average Reviews Per Month by Neighborhood\n",
    "    plot_bar(location_stats,\n",
    "             x='neighbourhood',\n",
    "             y='Average Reviews Per Month',\n",
    "             title='Average Reviews Per Month by Neighborhood',\n",
    "             xlabel='Neighborhood',\n",
    "             ylabel='Average Reviews Per Month',\n",
    "             hue='neighbourhood',  # Specify hue for coloring\n",
    "             rotation=45)\n",
    "\n",
    "\n",
    "analyze_location_trends(df)                  # Explore trends by location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the room type affect the average price and availability of listings?\n",
    "  \n",
    "Room type can affect pricing, availability, and customer preferences.  \n",
    "- This analysis uncovers trends in the distribution and popularity of room types.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Analyze Room Type Trends\n",
    "def analyze_room_type_trends(df):\n",
    "    \"\"\"\n",
    "    Analyze trends in average price and availability based on room type.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input DataFrame containing Airbnb data.\n",
    "\n",
    "    Returns:\n",
    "    None: Displays bar plots for room type trends.\n",
    "    \"\"\"\n",
    "    if 'room_type' not in df.columns or 'price' not in df.columns:\n",
    "        raise ValueError(\n",
    "            \"DataFrame must contain 'room_type' and 'price' columns.\")\n",
    "\n",
    "    # Group by room type\n",
    "    room_type_stats = df.groupby('room_type').agg({\n",
    "        'price': 'mean',\n",
    "        'availability_365': 'mean'\n",
    "    }).reset_index().round(2)\n",
    "\n",
    "    # Save summary to CSV\n",
    "    room_type_stats.to_csv(\"room_type_trends.csv\", index=False)\n",
    "\n",
    "    # Bar plot: Average Price by Room Type\n",
    "    plot_bar(room_type_stats,\n",
    "             x='room_type',\n",
    "             y='price',\n",
    "             title='Average Price by Room Type',\n",
    "             xlabel='Room Type',\n",
    "             ylabel='Average Price ($)',\n",
    "             hue='room_type',  # Specify hue for coloring\n",
    "             rotation=45)\n",
    "\n",
    "    # Bar plot: Average Availability by Room Type\n",
    "    plot_bar(room_type_stats,\n",
    "             x='room_type',\n",
    "             y='availability_365',\n",
    "             title='Average Availability by Room Type',\n",
    "             xlabel='Room Type',\n",
    "             ylabel='Average Availability (Days)',\n",
    "             hue='room_type',  # Specify hue for coloring\n",
    "             rotation=45)\n",
    "\n",
    "\n",
    "# Examine room type distribution and trends\n",
    "analyze_room_type_trends(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do listings with more frequent reviews tend to have higher/lower prices or higher/lower availability?\n",
    " \n",
    "Reviews provide customer feedback and can influence:  \n",
    "- Listing visibility.  \n",
    "- Booking rates.  \n",
    "We analyze how the number and quality of reviews impact various aspects of the listings.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13.Analyze review impact\n",
    "def analyze_review_impact(df):\n",
    "    \"\"\"\n",
    "    Analyze the impact of the number of reviews on pricing and ratings.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame containing Airbnb data.\n",
    "\n",
    "    Returns:\n",
    "    None: Displays scatter plots and correlation values for the analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    # Correlation values\n",
    "    correlation_price = df['number_of_reviews'].corr(df['price'])\n",
    "    correlation_reviews_month = df['number_of_reviews'].corr(\n",
    "        df['reviews_per_month'])\n",
    "\n",
    "    print(f\"Correlation between number of reviews and price: {\n",
    "          correlation_price:.2f}\")\n",
    "    print(f\"Correlation between number of reviews and reviews per month: {\n",
    "          correlation_reviews_month:.2f}\")\n",
    "\n",
    "    # Scatter plot: Number of Reviews vs. Price\n",
    "    plot_scatter('number_of_reviews', 'price', df,\n",
    "                 'Number of Reviews vs. Price',\n",
    "                 'Number of Reviews',\n",
    "                 'Price ($)',\n",
    "                 hue='room_type')\n",
    "\n",
    "    # Scatter plot: Number of Reviews vs. Reviews Per Month\n",
    "    plot_scatter('number_of_reviews', 'reviews_per_month', df,\n",
    "                 'Number of Reviews vs. Reviews per Month',\n",
    "                 'Number of Reviews',\n",
    "                 'Reviews per Month',\n",
    "                 hue='room_type')\n",
    "\n",
    "\n",
    "# Assess the impact of reviews on listings\n",
    "analyze_review_impact(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
